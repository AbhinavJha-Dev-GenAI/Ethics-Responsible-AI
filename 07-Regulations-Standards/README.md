# 07. Regulations & Standards ğŸ“œğŸ“¡

Compliance is no longer optional for AI. Governments worldwide are creating frameworks to ensure AI safety and privacy.

## 1. The EU AI Act ğŸ‡ªğŸ‡º

The world's first comprehensive AI law based on **Risk Levels**:
*   **Unacceptable Risk**: (e.g., Social scoring, biometric identification in public). BANNED.
*   **High Risk**: (e.g., Recruitment, Credit scoring, Healthcare). Requires strict auditing, documentation, and human oversight.
*   **Limited Risk**: (e.g., Chatbots). Requires transparency (users must know they are talking to an AI).

---

## 2. NIST AI Risk Management Framework (RMF) ğŸ‡ºğŸ‡¸

A voluntary framework used in the US to manage AI risks.
1.  **Govern**: Culture and internal policies.
2.  **Map**: Identifying risks and context.
3.  **Measure**: Testing and evaluation.
4.  **Manage**: Mitigation and ongoing monitoring.

---

## 3. Privacy Laws (GDPR, CCPA) ğŸ”

These focus on how training data is collected and stored.
- **Right to be Forgotten**: Can you "unlearn" a specific user's data from a model? (Machine Unlearning).
- **Consent**: Explicit permission needed for using data for training.

---

## ğŸ› ï¸ Essential Checklist for Developers
- [ ] Is my model "High Risk" under the EU AI Act?
- [ ] Do I have an audit trail of the training data?
- [ ] Have I performed an "AI Impact Assessment"?
- [ ] is my system status page clear about AI usage?

---

## ğŸ“‰ Summary
Regulatory compliance is becoming as important as model performance. Engineers who understand these frameworks are highly valuable to enterprise teams.
